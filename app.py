# app.py (N·∫±m ngo√†i th∆∞ m·ª•c src)

import streamlit as st
from PIL import Image
import os
import io
import time
import uuid

# --- THAY ƒê·ªîI: D√πng Import Tuy·ªát ƒë·ªëi ---
from src.inference import predict_kie
from src.ocr_engine import visualize_ocr 
# from src.utils import unnormalize_box # Kh√¥ng c·∫ßn unnormalize_box trong app.py

# --- C·∫•u h√¨nh Streamlit ---
st.set_page_config(
    page_title="Vietnamese Receipt KIE App",
    layout="wide",
    initial_sidebar_state="expanded",
)

st.title("üßæ Tr√≠ch xu·∫•t D·ªØ li·ªáu H√≥a ƒë∆°n Ti·∫øng Vi·ªát (LayoutLM + Tesseract/pytesseract)")
st.write("·ª®ng d·ª•ng Data Mining/KIE s·ª≠ d·ª•ng LayoutLM v√† Tesseract (pytesseract) ƒë·ªÉ nh·∫≠n d·∫°ng Ng∆∞·ªùi b√°n, Ng√†y v√† T·ªïng ti·ªÅn.")

# T·∫°o th∆∞ m·ª•c t·∫°m th·ªùi ƒë·ªÉ l∆∞u ·∫£nh
TEMP_DIR = "temp_uploads"
os.makedirs(TEMP_DIR, exist_ok=True)

# --- Ch·ª©c nƒÉng ch√≠nh ---

uploaded_file = st.file_uploader("T·∫£i l√™n h√¨nh ·∫£nh h√≥a ƒë∆°n (JPEG/PNG)", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    # 1. L∆∞u file t·∫°m th·ªùi
    file_bytes = uploaded_file.read()
    temp_filename = os.path.join(TEMP_DIR, f"{uuid.uuid4().hex}_{uploaded_file.name}")
    with open(temp_filename, "wb") as f:
        f.write(file_bytes)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("·∫¢nh H√≥a ƒë∆°n")
        image = Image.open(io.BytesIO(file_bytes))
        st.image(image, use_container_width=True)

    with col2:
        st.subheader("K·∫øt qu·∫£ Tr√≠ch xu·∫•t")
        
        if st.button("Tr√≠ch xu·∫•t Th√¥ng tin", key="extract_btn"):
            with st.spinner('ƒêang ch·∫°y OCR v√† d·ª± ƒëo√°n LayoutLM...'):
                start_time = time.time()
                
                # 2. Ch·∫°y pipeline d·ª± ƒëo√°n
                results = predict_kie(temp_filename)
                
                end_time = time.time()
                
                if isinstance(results, dict) and 'error' in results:
                    st.error(results['error'])
                else:
                    final_results, extracted_details = results
                    
                    st.success(f"Tr√≠ch xu·∫•t ho√†n t·∫•t trong {end_time - start_time:.2f} gi√¢y!")
                    
                    # 3. Hi·ªÉn th·ªã k·∫øt qu·∫£ g·ªôp
                    st.json(final_results)
                    
                    # 4. (T√πy ch·ªçn) Hi·ªÉn th·ªã ·∫£nh k√®m Bounding Box
                    st.markdown("---")
                    st.subheader("Tr·ª±c quan h√≥a OCR")
                    
                    # L·∫•y d·ªØ li·ªáu t·ª´ extracted_details
                    viz_words = []
                    viz_boxes = []
                    for key, items in extracted_details.items():
                        for item in items:
                            viz_words.append(item['text'])
                            viz_boxes.append(item['box'])
                            
                    # V·∫Ω b·∫±ng h√†m visualize_ocr t·ª´ src/ocr_engine.py
                    try:
                        annotated_image = visualize_ocr(temp_filename, viz_boxes, viz_words)
                        st.image(annotated_image, caption="C√°c tr∆∞·ªùng quan tr·ªçng ƒë∆∞·ª£c ƒë√°nh d·∫•u", use_container_width=True)
                    except Exception as e:
                        st.warning(f"Kh√¥ng th·ªÉ tr·ª±c quan h√≥a: {e}")

    # 5. D·ªçn d·∫πp file t·∫°m
    if os.path.exists(temp_filename):
        os.remove(temp_filename)